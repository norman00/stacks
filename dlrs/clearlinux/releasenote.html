

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deep Learning Reference Stack Release Notes &mdash; System Stacks for Linux* OS  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Deep Learning Reference Stack Terms of Use" href="../terms_of_use.html" />
    <link rel="prev" title="Deep Learning Reference Stack README" href="../README.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> System Stacks for Linux* OS
          

          
            
            <img src="../../_static/stacks_logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../README.html">System Stacks for Linux* OS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../README.html#contributing">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../README.html#security-issues">Security Issues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../README.html#mailing-list">Mailing List</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Deep Learning Reference Stack</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#overview">Overview</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../README.html">Deep Learning Reference Stack README</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Deep Learning Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-deep-learning-reference-stack-release">The Deep Learning Reference Stack Release</a></li>
<li class="toctree-l4"><a class="reference internal" href="#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#working-with-the-deep-learning-reference-stack">Working with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="#performance-tuning-configurations">Performance tuning configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#contributing-to-the-deep-learning-reference-stack">Contributing to the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../terms_of_use.html">Deep Learning Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dlrs.html">Deep Learning Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#tensorflow-single-and-multi-node-benchmarks">TensorFlow single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#pytorch-single-and-multi-node-benchmarks">PyTorch single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#tensorflow-training-tfjob-with-kubeflow-and-dlrs">TensorFlow Training (TFJob) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#pytorch-training-pytorch-job-with-kubeflow-and-dlrs">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#working-with-horovod-and-openmpi">Working with Horovod* and OpenMPI*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#using-transformers-for-natural-language-processing">Using Transformers* for Natural Language Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#using-the-openvino-model-optimizer">Using the OpenVINO™ Model Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#using-the-openvino-toolkit-inference-engine">Using the OpenVINO™ toolkit Inference Engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#using-seldon-and-openvino-model-server-with-the-deep-learning-reference-stack">Using Seldon and OpenVINO™ model server with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#use-jupyter-notebook">Use Jupyter Notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#uninstallation">Uninstallation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#compiling-aixprt-with-openmp-on-dlrs">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs.html#related-topics">Related topics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="README.html">Deep Learning Reference Stack containers based on Clear Linux OS</a></li>
<li class="toctree-l3"><a class="reference internal" href="ml-compiler/README.html">System Stacks Deep Learning Compiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ml-compiler/README.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="ml-compiler/README.html#build-args">Build ARGs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#pytorch-versions">PyTorch versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pytorch/mkl/README.html">Deep Learning Reference Stack with Pytorch and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch/oss/README.html">Deep Learning Reference Stack with Pytorch and OpenBLAS</a></li>
<li class="toctree-l4"><a class="reference internal" href="pytorch/oss/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#tensorflow-versions">TensorFlow versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensorflow/mkl/README.html">Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow/mkl/scripts/README.html">Deep Learning Reference Stack Scripts</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow/oss/README.html">Deep Learning Reference Stack with Tensorflow and Optimized Eigen</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow/oss/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_2/mkl/README.html">Deep Learning Reference Stack with TensorFlow 2.0 and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_2/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_2/mkl/scripts/README.html">Deep Learning Reference Stack Scripts</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dars/index.html">Data Analytics Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dars/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dars/clearlinux/releasenote.html">Data Analytics Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#stack-features">Stack Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#the-data-analytics-reference-stack-with-mkl">The Data Analytics Reference Stack with MKL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#the-data-analytics-reference-stack-with-openblas">The Data Analytics Reference Stack with OpenBLAS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#working-with-the-data-analytics-reference-stack">Working with the Data Analytics Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#contributing-to-the-database-reference-stack">Contributing to the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/clearlinux/releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/terms_of_use.html">Data Analytics Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../dars/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dars/dars.html">Data Analytics Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dars/dars.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/dars.html#using-the-docker-images">Using the Docker images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/dars.html#using-apache-spark-in-dars">Using Apache Spark* in DARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/dars.html#using-apache-hadoop-in-dars">Using Apache Hadoop in DARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/dars.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/dars.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../dars/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dars/clearlinux/README.html">Data Analytics Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/index.html#openblas-versions">OpenBLAS versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html">Data Analytics Reference Stack with OpenBLAS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#java-requirements">Java Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#single-node-hadoop-cluster-setup">Single Node Hadoop Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#inside-the-running-container-we-need-to-edit-hadoop-configuration-files-as-follows">Inside the running container we need to edit hadoop configuration files as follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#start-hadoop-daemons">Start Hadoop daemons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#single-node-spark-cluster-setup">Single Node Spark Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#run-the-pi-calculator-example-on-spark-shell">Run the Pi Calculator Example on spark-shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#run-the-pi-calculator-example-on-pyspark">Run the Pi Calculator Example on pyspark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#kubernetes-installation">Kubernetes installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/README.html#faq"><strong>FAQ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/openblas/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dars/index.html#mkl-versions">MKL versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html">Data Analytics Reference Stack with Intel® MKL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#java-requirements">Java Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#single-node-hadoop-cluster-setup">Single Node Hadoop Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#inside-the-running-container-we-need-to-edit-hadoop-configuration-files-as-follows">Inside the running container we need to edit hadoop configuration files as follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#start-hadoop-daemons">Start Hadoop daemons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#single-node-spark-cluster-setup">Single Node Spark Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#run-the-pi-calculator-example-on-spark-shell">Run the Pi Calculator Example on spark-shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#run-the-pi-calculator-example-on-pyspark">Run the Pi Calculator Example on pyspark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#kubernetes-installation">Kubernetes installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/README.html#faq"><strong>FAQ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dars/clearlinux/mkl/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dbrs/index.html">Database Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dbrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/README.html">Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/releasenote.html">Database Reference Stack Release Note</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/releasenote.html#the-database-reference-stack-releases">The Database Reference Stack Releases</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/releasenote.html#the-database-reference-stack-with-cassandra">The Database Reference Stack with Cassandra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/releasenote.html#the-database-reference-stack-with-redis">The Database Reference Stack with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/releasenote.html#the-database-reference-stack-with-memcached">The Database Reference Stack with Memcached</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/releasenote.html#how-to-get-the-database-reference-stack">How to get the Database Reference Stack</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/releasenote.html#working-with-the-database-reference-stack">Working with the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/releasenote.html#contributing-to-the-database-reference-stack">Contributing to the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/terms_of_use.html">Database Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../dbrs/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/dbrs.html">Database Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#hardware-requirements">Hardware Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#firmware-configuration">Firmware configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#hardware-configuration">Hardware Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#running-dbrs-with-apache-cassandra">Running DBRS with Apache Cassandra*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#deploy-an-apache-cassandra-pmem-cluster-on-kubernetes">Deploy An Apache Cassandra-PMEM cluster on Kubernetes*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#running-dbrs-with-redis">Running DBRS with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/dbrs.html#running-dbrs-with-memcached">Running DBRS with Memcached</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../dbrs/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/clearlinux/redis/README.html">Database Reference Stack with Redis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/redis/README.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/redis/README.html#clone-the-repository">Clone the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/redis/README.html#run-dbrs-redis-as-a-standalone-container">Run DBRS Redis as a standalone container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/redis/README.html#deploy-dbrs-redis-cluster-on-kubernetes">Deploy DBRS Redis cluster on Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/clearlinux/redis/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/index.html#apache-cassandra-versions">Apache Cassandra* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/cassandra/README.html">Database Reference Stack with Cassandra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/cassandra/cassandra-pmem-helm/files/conf/README.html">Configuration files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/cassandra/cassandra-pmem-helm/files/testProfiles/README.html">Test profiles</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/cassandra/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/index.html#memcached-versions">memcached versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/memcached/README.html">Memcached DBRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/memcached/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/index.html#redis-versions">REDIS versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/redis/README.html">Database Reference Stack with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/clearlinux/redis/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../dbrs/index.html#centos-based-containers">CentOS based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/centos8/memcached/README.html">Memcached DBRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/centos8/memcached/README.html#build-dbrs-memcached-image">Build DBRS Memcached image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dbrs/centos8/memcached/README.html#run-dbrs-memcached-as-a-standalone-container">Run DBRS Memcached as a standalone container</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../dbrs/centos8/memcached/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../mers/index.html">Media Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mers/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mers/README.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../mers/README.html#source-code">Source Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/README.html#supported-platforms-and-media-codecs">Supported Platforms and Media Codecs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../mers/releasenotes.html">Media Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#the-media-reference-stack">The Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#the-media-reference-stack-licenses">The Media Reference Stack licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#disclaimer">Disclaimer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#source-code">Source code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#contributing-to-the-media-reference-stack">Contributing to the Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/releasenotes.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../mers/terms_of_use.html">Media Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mers/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mers/mers.html">Media Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../mers/mers.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/mers.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/mers.html#get-the-pre-built-mers-container-image">Get the pre-built MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/mers.html#build-the-mers-container-image-from-source">Build the MeRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/mers.html#use-the-mers-container-image">Use the MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/mers.html#add-aom-support">Add AOM support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mers/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mers/clearlinux/INSTALL.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../mers/clearlinux/INSTALL.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/clearlinux/INSTALL.html#pulling-from-docker-hub">Pulling from Docker Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/clearlinux/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mers/clearlinux/INSTALL.html#run-examples">Run examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../hpcrs/index.html">High Performance Computing Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../hpcrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../hpcrs/README.html">High Performance Compute Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#stack-features">Stack features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#get-the-pre-built-hpcrs-container-image">Get the pre-built HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#build-the-hpcrs-container-image-from-source">Build the HPCRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#use-the-hpcrs-container-image">Use the HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#convert-the-hpcrs-image-to-a-singularity-image">Convert the HPCRS image to a Singularity image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/README.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../hpcrs/NEWS.html">Release notes for HPCRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/NEWS.html#release-v0-1-0">Release <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code> :</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../hpcrs/terms_of_use.html">High Performance Computing Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../hpcrs/index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../hpcrs/d2s/Readme.html">d2s - A wrapper used to convert Docker images to Singularity images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/d2s/Readme.html#version-compatibility">Version compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/d2s/Readme.html#install-singularity">Install Singularity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/d2s/Readme.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/d2s/Readme.html#download-compile-singularity">Download &amp; Compile <em>Singularity</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../hpcrs/d2s/Readme.html#source-bash-completion-file-optional">Source bash completion file (Optional)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../hpcrs/docs/FAQ.html">HPCRS Frequently Asked Questions (FAQ)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks">Project GitHub repository</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">System Stacks for Linux* OS</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Deep Learning Reference Stack</a> &raquo;</li>
        
      <li>Deep Learning Reference Stack Release Notes</li>
    
    

  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="deep-learning-reference-stack-release-notes">
<h1>Deep Learning Reference Stack Release Notes<a class="headerlink" href="#deep-learning-reference-stack-release-notes" title="Permalink to this headline">¶</a></h1>
<p>The Deep Learning Reference Stack is an integrated, highly-performant open source stack optimized for Intel® Xeon® Scalable platforms. This open source community release is part of our effort to ensure AI developers have easy access to all of the features and functionality of the Intel platforms.  The Deep Learning Reference Stack is highly-tuned and built for cloud native environments. With this stack, we are enabling developers to quickly prototype by reducing the complexity associated with integrating multiple software components, while still giving users the flexibility to customize their solutions. This version includes additional components to provide greater flexibility and a more comprehensive take on the deep learning environment.</p>
<div class="section" id="the-deep-learning-reference-stack-release">
<h2>The Deep Learning Reference Stack Release<a class="headerlink" href="#the-deep-learning-reference-stack-release" title="Permalink to this headline">¶</a></h2>
<p>To offer more flexibility, we are releasing multiple versions of the Deep Learning Reference Stack. All versions are built on top of the Clear Linux OS, which is optimized for IA.</p>
<blockquote>
<div><p><strong>Note:</strong>
The minimum validated version of Clear Linux for this stack is 32690.</p>
</div></blockquote>
<div class="section" id="the-deep-learning-reference-stack-with-tensorflow-2-2-onednn-and-intel-avx512-deep-learning-boost">
<h3>The Deep Learning Reference Stack with Tensorflow 2.2, oneDNN and Intel® AVX512-Deep Learning Boost<a class="headerlink" href="#the-deep-learning-reference-stack-with-tensorflow-2-2-onednn-and-intel-avx512-deep-learning-boost" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow2-clearlinux/">dlrs-tensorflow2-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>TensorFlow 2.2.0-rc0 optimized using oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>Intel OpenVINO™ model server v2020.1</p></li>
<li><p>Transformers - State-of-the-art Natural Language Processing for TensorFlow 2.2.0-rc0</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</div>
<div class="section" id="the-deep-learning-reference-stack-with-tensorflow-1-15-onednn-and-intel-avx512-deep-learning-boost">
<h3>The Deep Learning Reference Stack with Tensorflow 1.15, oneDNN and Intel® AVX512-Deep Learning Boost<a class="headerlink" href="#the-deep-learning-reference-stack-with-tensorflow-1-15-onednn-and-intel-avx512-deep-learning-boost" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux/">dlrs-tensorflow-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>TensorFlow 1.15 optimized using oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>Intel OpenVINO™ model server v2020.1</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</div>
<div class="section" id="the-deep-learning-reference-stack-with-eigen">
<h3>The Deep Learning Reference Stack with Eigen<a class="headerlink" href="#the-deep-learning-reference-stack-with-eigen" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux/">dlrs-tensorflow-clearlinux:v0.6.0-oss</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>TensorFlow 2.0 compiled with AVX2 and AVX512 optimizations</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>Jupyter-notebook 6.0.3</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</div>
<div class="section" id="the-deep-learning-reference-stack-with-pytorch-and-intel-mkl">
<h3>The Deep Learning Reference Stack with PyTorch and Intel® MKL<a class="headerlink" href="#the-deep-learning-reference-stack-with-pytorch-and-intel-mkl" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux/">dlrs-pytorch-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>PyTorch version 1.4.0 optimized using Intel® Math Kernel Library, oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>PyTorch lightning version v0.6.0</p></li>
<li><p>Transformers - State-of-the-art Natural Language Processing for PyTorch 1.14</p></li>
<li><p>Flair for Natural Language Processing version v0.4.5</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</div>
<div class="section" id="the-deep-learning-reference-stack-with-pytorch">
<h3>The Deep Learning Reference Stack with PyTorch<a class="headerlink" href="#the-deep-learning-reference-stack-with-pytorch" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux/">dlrs-pytorch-clearlinux:v0.6.0-oss</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>PyTorch version 1.4.0 with OpenBLAS version 0.3.9</p></li>
<li><p>Jupyter-notebook 6.0.3</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</div>
<div class="section" id="deep-learning-compilers">
<h3>Deep Learning Compilers<a class="headerlink" href="#deep-learning-compilers" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-ml-compiler-clearlinux/">dlrs-ml-compiler-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>TVM version 0.6 optimized using the Intel® Math Kernel Library</p></li>
<li><p>Jupyter-notebook 6.0.3</p></li>
</ul>
</div>
<div class="section" id="how-to-get-the-deep-learning-reference-stack">
<h3>How to get the Deep Learning Reference Stack<a class="headerlink" href="#how-to-get-the-deep-learning-reference-stack" title="Permalink to this headline">¶</a></h3>
<p>The official Deep Learning Reference Stack Docker images are hosted at: https://hub.docker.com/r/sysstacks/.</p>
<blockquote>
<div><p><strong>Note:</strong>
The System Stacks team is transitioning into a new organization in Github and Dockerhub, please note all images are now under the <code class="docutils literal notranslate"><span class="pre">sysstacks</span></code> namespace.</p>
</div></blockquote>
<ul class="simple">
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux">Tensorflow 1.15 and oneDNN version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow2-clearlinux">Tensorflow 2.2.0-rc0 and oneDNN version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux">Tensorflow with Eigen version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux">PyTorch with oneDNN and Intel® MKL version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux">PyTorch with OpenBLAS version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-ml-compiler-clearlinux">ML Compiler with Intel® MKL version</a></p></li>
</ul>
<blockquote>
<div><p><strong>Note:</strong>
To take advantage of the AVX-512, and AVX-512 Deep Learning Boost functionality with the Deep Learning Reference Stack, please use the following hardware:
* AVX 512 images require an Intel® Xeon® Scalable Platform
* AVX-512 Deep Learning Boost requires a Second-Generation Intel® Xeon® Scalable Platform</p>
</div></blockquote>
</div>
</div>
<div class="section" id="licensing">
<h2>Licensing<a class="headerlink" href="#licensing" title="Permalink to this headline">¶</a></h2>
<p>The Deep Learning Reference Stack is guided by these <a class="reference external" href="https://clearlinux.org/stacks/deep-learning/terms-of-use">Terms of Use</a>. The Docker images are hosted on https://hub.docker.com and as with all Docker images, these likely also contain other software which may be under other licenses (such as Bash, etc. from the base distribution, along with any direct or indirect dependencies of the primary software being contained).</p>
</div>
<div class="section" id="working-with-the-deep-learning-reference-stack">
<h2>Working with the Deep Learning Reference Stack<a class="headerlink" href="#working-with-the-deep-learning-reference-stack" title="Permalink to this headline">¶</a></h2>
<p>The Deep Learning Reference Stack includes TensorFlow and Kubeflow support.
These software components were selected because they are most popular/widely used by developers and CSPs. Clear Linux provides optimizations across the entire OS stack for the ultimate end user performance and is customizable to meet your unique needs. TensorFlow was selected as it is the leading deep learning and machine learning framework. oneAPI Deep Neural Network Library (oneDNN) is an open source performance library for Deep Learning (DL) applications intended for acceleration of DL frameworks on Intel® architecture. Intel® oneDNN includes highly vectorized and threaded building blocks to implement convolutional neural networks (CNN) with C and C++ interfaces.  Kubeflow  is a project that provides a straightforward way to deploy simple, scalable and portable Machine Learning workflows on Kubernetes. This combination of an operating system and the deep learning framework and libraries results in a performant deep learning software stack.</p>
<p>Please refer to the <a class="reference external" href="https://docs.01.org/clearlinux/latest/guides/stacks/dlrs.html">Deep Learning Reference Stack guide</a> for detailed instructions for running the TensorFlow and Kubeflow Benchmarks on the docker images.</p>
<blockquote>
<div><p><strong>Note:</strong>
Although the DLRS images and dockerfiles may be modified for your needs, there are some modifications that may cause unexpected or undesirable results. For example, using the Clear Linux <code class="docutils literal notranslate"><span class="pre">swupd</span> <span class="pre">bundle-add</span></code> command to add packages to a Clear Linux based container may overwrite the DLRS core components. Please use care when modifying the contents of the containers. A listing of the core components can be found in the <a class="reference external" href="https://github.com/intel/stacks/blob/master/dlrs/clearlinux/releasenote">release notes</a> for each release.</p>
</div></blockquote>
</div>
<div class="section" id="performance-tuning-configurations">
<h2>Performance tuning configurations<a class="headerlink" href="#performance-tuning-configurations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="single-node-configuration">
<h3>Single Node Configuration<a class="headerlink" href="#single-node-configuration" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_inter_threads</td>
<td>Socket number</td>
</tr>
<tr>
<td>num_intra_threads</td>
<td>Physical cores number</td>
</tr>
<tr>
<td>data_format</td>
<td>NHWC for Eigen; NCHW for MKL as MKL is optimized for this format</td>
</tr>
</tbody>
</table><p>Example: For Intel® Xeon® Gold 6140 CPU &#64; 2.30GHz with 2 Sockets and 18 Cores/Socket MKL training with batch size 32:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="n">python</span> <span class="n">tf_cnn_benchmarks</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device</span><span class="o">=</span><span class="n">cpu</span> <span class="o">--</span><span class="n">mkl</span><span class="o">=</span><span class="kc">True</span> <span class="o">--</span><span class="n">nodistortions</span> <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="n">resnet50</span> <span class="o">--</span><span class="n">data_format</span><span class="o">=</span><span class="n">NCHW</span> <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span> <span class="o">--</span><span class="n">num_inter_threads</span><span class="o">=</span><span class="mi">2</span> <span class="o">--</span><span class="n">num_intra_threads</span><span class="o">=</span><span class="mi">36</span> <span class="o">--</span><span class="n">data_dir</span><span class="o">=/</span><span class="n">imagenet</span><span class="o">-</span><span class="n">TFrecord</span> <span class="o">--</span><span class="n">data_name</span><span class="o">=</span><span class="n">imagenet</span>
</pre></div>
</div>
</div>
<div class="section" id="multi-node-configuration">
<h3>Multi-node Configuration<a class="headerlink" href="#multi-node-configuration" title="Permalink to this headline">¶</a></h3>
<p>The Deep Learning Reference Stack can be used in a multi node configuration using Kubernetes and different machine learning frameworks and libraries. Please refer to the System Stacks <a class="reference external" href="https://github.com/intel/stacks-usecase">usecases repo</a> to find examples on how to setup the Deep Learning Reference Stack with Kubeflow for multi-node.</p>
<p>For multi-node training please refer to:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.01.org/clearlinux/latest/guides/stacks/dlrs.html#id12">PyTorch multi-node using Kubeflow</a></p></li>
<li><p><a class="reference external" href="https://docs.01.org/clearlinux/latest/guides/stacks/dlrs.html#id11">Tensorflow multi-node using Kubeflow</a></p></li>
</ul>
</div>
</div>
<div class="section" id="contributing-to-the-deep-learning-reference-stack">
<h2>Contributing to the Deep Learning Reference Stack<a class="headerlink" href="#contributing-to-the-deep-learning-reference-stack" title="Permalink to this headline">¶</a></h2>
<p>We encourage your contributions to this project, through the established Clear Linux community tools.  Our team uses typical open source collaboration tools that are described on the Clear Linux <a class="reference external" href="https://clearlinux.org/community">community page</a>.</p>
</div>
<div class="section" id="reporting-security-issues">
<h2>Reporting Security Issues<a class="headerlink" href="#reporting-security-issues" title="Permalink to this headline">¶</a></h2>
<p>If you have discovered potential security vulnerability in an Intel product, please contact the iPSIRT at secure&#64;intel.com.</p>
<p>It is important to include the following details:</p>
<ul class="simple">
<li><p>The products and versions affected</p></li>
<li><p>Detailed description of the vulnerability</p></li>
<li><p>Information on known exploits</p></li>
</ul>
<p>Vulnerability information is extremely sensitive. The iPSIRT strongly recommends that all security vulnerability reports sent to Intel be encrypted using the iPSIRT PGP key. The PGP key is available here: https://www.intel.com/content/www/us/en/security-center/pgp-public-key.html</p>
<p>Software to encrypt messages may be obtained from:</p>
<ul class="simple">
<li><p>PGP Corporation</p></li>
<li><p>GnuPG</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../terms_of_use.html" class="btn btn-neutral float-right" title="Deep Learning Reference Stack Terms of Use" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../README.html" class="btn btn-neutral float-left" title="Deep Learning Reference Stack README" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>