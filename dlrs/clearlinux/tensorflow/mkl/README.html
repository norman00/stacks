

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN) &mdash; System Stacks for Linux* OS  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Additional details on licenses" href="licenses/README.html" />
    <link rel="prev" title="Additional details on licenses" href="../../pytorch/oss/licenses/README.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> System Stacks for Linux* OS
          

          
            
            <img src="../../../../_static/stacks_logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../README.html">System Stacks for Linux* OS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../README.html#contributing">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../README.html#security-issues">Security Issues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../README.html#mailing-list">Mailing List</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">Deep Learning Reference Stack</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../README.html">Deep Learning Reference Stack README</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../releasenote.html">Deep Learning Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../releasenote.html#the-deep-learning-reference-stack-release">The Deep Learning Reference Stack Release</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../releasenote.html#working-with-the-deep-learning-reference-stack">Working with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../releasenote.html#performance-tuning-configurations">Performance tuning configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../releasenote.html#contributing-to-the-deep-learning-reference-stack">Contributing to the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../terms_of_use.html">Deep Learning Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dlrs.html">Deep Learning Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#tensorflow-single-and-multi-node-benchmarks">TensorFlow single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#pytorch-single-and-multi-node-benchmarks">PyTorch single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#tensorflow-training-tfjob-with-kubeflow-and-dlrs">TensorFlow Training (TFJob) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#pytorch-training-pytorch-job-with-kubeflow-and-dlrs">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#working-with-horovod-and-openmpi">Working with Horovod* and OpenMPI*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#using-transformers-for-natural-language-processing">Using Transformers* for Natural Language Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#using-the-openvino-model-optimizer">Using the OpenVINO™ Model Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#using-the-openvino-toolkit-inference-engine">Using the OpenVINO™ toolkit Inference Engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#using-seldon-and-openvino-model-server-with-the-deep-learning-reference-stack">Using Seldon and OpenVINO™ model server with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#use-jupyter-notebook">Use Jupyter Notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#uninstallation">Uninstallation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#compiling-aixprt-with-openmp-on-dlrs">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../dlrs.html#related-topics">Related topics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../index.html#clear-linux-based-containers">Clear Linux based containers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../README.html">Deep Learning Reference Stack containers based on Clear Linux OS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ml-compiler/README.html">System Stacks Deep Learning Compiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../ml-compiler/README.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ml-compiler/README.html#build-args">Build ARGs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../index.html#pytorch-versions">PyTorch versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../pytorch/mkl/README.html">Deep Learning Reference Stack with Pytorch and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../pytorch/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../pytorch/oss/README.html">Deep Learning Reference Stack with Pytorch and OpenBLAS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../pytorch/oss/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="reference internal" href="../../../index.html#tensorflow-versions">TensorFlow versions</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="scripts/README.html">Deep Learning Reference Stack Scripts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../oss/README.html">Deep Learning Reference Stack with Tensorflow and Optimized Eigen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../oss/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../tensorflow_2/mkl/README.html">Deep Learning Reference Stack with TensorFlow 2.0 and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../tensorflow_2/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../tensorflow_2/mkl/scripts/README.html">Deep Learning Reference Stack Scripts</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dars/index.html">Data Analytics Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../dars/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html">Data Analytics Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#stack-features">Stack Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#the-data-analytics-reference-stack-with-mkl">The Data Analytics Reference Stack with MKL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#the-data-analytics-reference-stack-with-openblas">The Data Analytics Reference Stack with OpenBLAS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#working-with-the-data-analytics-reference-stack">Working with the Data Analytics Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#contributing-to-the-database-reference-stack">Contributing to the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/clearlinux/releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/terms_of_use.html">Data Analytics Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../dars/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/dars.html">Data Analytics Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/dars.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/dars.html#using-the-docker-images">Using the Docker images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/dars.html#using-apache-spark-in-dars">Using Apache Spark* in DARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/dars.html#using-apache-hadoop-in-dars">Using Apache Hadoop in DARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/dars.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/dars.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../dars/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/clearlinux/README.html">Data Analytics Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/index.html#openblas-versions">OpenBLAS versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html">Data Analytics Reference Stack with OpenBLAS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#java-requirements">Java Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#single-node-hadoop-cluster-setup">Single Node Hadoop Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#inside-the-running-container-we-need-to-edit-hadoop-configuration-files-as-follows">Inside the running container we need to edit hadoop configuration files as follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#start-hadoop-daemons">Start Hadoop daemons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#single-node-spark-cluster-setup">Single Node Spark Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#run-the-pi-calculator-example-on-spark-shell">Run the Pi Calculator Example on spark-shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#run-the-pi-calculator-example-on-pyspark">Run the Pi Calculator Example on pyspark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#kubernetes-installation">Kubernetes installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/README.html#faq"><strong>FAQ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/openblas/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dars/index.html#mkl-versions">MKL versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html">Data Analytics Reference Stack with Intel® MKL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#java-requirements">Java Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#single-node-hadoop-cluster-setup">Single Node Hadoop Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#inside-the-running-container-we-need-to-edit-hadoop-configuration-files-as-follows">Inside the running container we need to edit hadoop configuration files as follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#start-hadoop-daemons">Start Hadoop daemons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#single-node-spark-cluster-setup">Single Node Spark Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#run-the-pi-calculator-example-on-spark-shell">Run the Pi Calculator Example on spark-shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#run-the-pi-calculator-example-on-pyspark">Run the Pi Calculator Example on pyspark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#kubernetes-installation">Kubernetes installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/README.html#faq"><strong>FAQ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dars/clearlinux/mkl/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dbrs/index.html">Database Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../dbrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/README.html">Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/releasenote.html">Database Reference Stack Release Note</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/releasenote.html#the-database-reference-stack-releases">The Database Reference Stack Releases</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/releasenote.html#the-database-reference-stack-with-cassandra">The Database Reference Stack with Cassandra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/releasenote.html#the-database-reference-stack-with-redis">The Database Reference Stack with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/releasenote.html#the-database-reference-stack-with-memcached">The Database Reference Stack with Memcached</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/releasenote.html#how-to-get-the-database-reference-stack">How to get the Database Reference Stack</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/releasenote.html#working-with-the-database-reference-stack">Working with the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/releasenote.html#contributing-to-the-database-reference-stack">Contributing to the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/terms_of_use.html">Database Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../dbrs/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/dbrs.html">Database Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#hardware-requirements">Hardware Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#firmware-configuration">Firmware configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#hardware-configuration">Hardware Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#running-dbrs-with-apache-cassandra">Running DBRS with Apache Cassandra*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#deploy-an-apache-cassandra-pmem-cluster-on-kubernetes">Deploy An Apache Cassandra-PMEM cluster on Kubernetes*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#running-dbrs-with-redis">Running DBRS with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/dbrs.html#running-dbrs-with-memcached">Running DBRS with Memcached</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../dbrs/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/README.html">Database Reference Stack with Redis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/README.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/README.html#clone-the-repository">Clone the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/README.html#run-dbrs-redis-as-a-standalone-container">Run DBRS Redis as a standalone container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/README.html#deploy-dbrs-redis-cluster-on-kubernetes">Deploy DBRS Redis cluster on Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/index.html#apache-cassandra-versions">Apache Cassandra* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/cassandra/README.html">Database Reference Stack with Cassandra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/cassandra/cassandra-pmem-helm/files/conf/README.html">Configuration files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/cassandra/cassandra-pmem-helm/files/testProfiles/README.html">Test profiles</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/cassandra/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/index.html#memcached-versions">memcached versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/memcached/README.html">Memcached DBRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/memcached/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/index.html#redis-versions">REDIS versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/README.html">Database Reference Stack with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/clearlinux/redis/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../dbrs/index.html#centos-based-containers">CentOS based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/centos8/memcached/README.html">Memcached DBRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/centos8/memcached/README.html#build-dbrs-memcached-image">Build DBRS Memcached image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dbrs/centos8/memcached/README.html#run-dbrs-memcached-as-a-standalone-container">Run DBRS Memcached as a standalone container</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../dbrs/centos8/memcached/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mers/index.html">Media Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../mers/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../mers/README.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/README.html#source-code">Source Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/README.html#supported-platforms-and-media-codecs">Supported Platforms and Media Codecs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../mers/releasenotes.html">Media Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#the-media-reference-stack">The Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#the-media-reference-stack-licenses">The Media Reference Stack licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#disclaimer">Disclaimer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#source-code">Source code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#contributing-to-the-media-reference-stack">Contributing to the Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/releasenotes.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../mers/terms_of_use.html">Media Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../mers/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../mers/mers.html">Media Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/mers.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/mers.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/mers.html#get-the-pre-built-mers-container-image">Get the pre-built MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/mers.html#build-the-mers-container-image-from-source">Build the MeRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/mers.html#use-the-mers-container-image">Use the MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/mers.html#add-aom-support">Add AOM support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../mers/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../mers/clearlinux/INSTALL.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/clearlinux/INSTALL.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/clearlinux/INSTALL.html#pulling-from-docker-hub">Pulling from Docker Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/clearlinux/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../mers/clearlinux/INSTALL.html#run-examples">Run examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hpcrs/index.html">High Performance Computing Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../hpcrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../hpcrs/README.html">High Performance Compute Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#stack-features">Stack features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#get-the-pre-built-hpcrs-container-image">Get the pre-built HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#build-the-hpcrs-container-image-from-source">Build the HPCRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#use-the-hpcrs-container-image">Use the HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#convert-the-hpcrs-image-to-a-singularity-image">Convert the HPCRS image to a Singularity image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/README.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../hpcrs/NEWS.html">Release notes for HPCRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/NEWS.html#release-v0-1-0">Release <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code> :</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../hpcrs/terms_of_use.html">High Performance Computing Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../hpcrs/index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../hpcrs/d2s/Readme.html">d2s - A wrapper used to convert Docker images to Singularity images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/d2s/Readme.html#version-compatibility">Version compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/d2s/Readme.html#install-singularity">Install Singularity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/d2s/Readme.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/d2s/Readme.html#download-compile-singularity">Download &amp; Compile <em>Singularity</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../hpcrs/d2s/Readme.html#source-bash-completion-file-optional">Source bash completion file (Optional)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../hpcrs/docs/FAQ.html">HPCRS Frequently Asked Questions (FAQ)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks">Project GitHub repository</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">System Stacks for Linux* OS</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Deep Learning Reference Stack</a> &raquo;</li>
        
      <li>Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)</li>
    
    

  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="deep-learning-reference-stack-with-tensorflow-and-intel-oneapi-deep-neural-network-library-onednn">
<h1>Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)<a class="headerlink" href="#deep-learning-reference-stack-with-tensorflow-and-intel-oneapi-deep-neural-network-library-onednn" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://microbadger.com/images/sysstacks/dlrs-tensorflow-clearlinux:v0.6.0"><img alt="https://images.microbadger.com/badges/image/sysstacks/dlrs-tensorflow-clearlinux:v0.6.0.svg" src="https://images.microbadger.com/badges/image/sysstacks/dlrs-tensorflow-clearlinux:v0.6.0.svg" /></a></p>
<div class="section" id="building-locally">
<h2>Building Locally<a class="headerlink" href="#building-locally" title="Permalink to this headline">¶</a></h2>
<p>Default build args in Docker are on: https://docs.docker.com/engine/reference/builder/#arg</p>
<blockquote>
<div><p>NOTE: This command is for locally building this image alone.</p>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">build</span> <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">cache</span> <span class="o">--</span><span class="n">build</span><span class="o">-</span><span class="n">arg</span> <span class="n">clear_ver</span><span class="o">=</span><span class="s2">&quot;32690&quot;</span> <span class="o">-</span><span class="n">t</span> <span class="n">dlrs</span><span class="o">-</span><span class="n">tensorflow</span><span class="o">-</span><span class="n">clearlinux</span><span class="p">:</span><span class="n">v0</span><span class="o">.</span><span class="mf">6.0</span> <span class="o">.</span>
</pre></div>
</div>
</div>
<div class="section" id="build-args">
<h2>Build ARGs<a class="headerlink" href="#build-args" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clear_ver</span></code> specifies the latest validated Clearlinux version for this DLRS Dockerfile.</p></li>
</ul>
<blockquote>
<div><p>NOTE: Changing this version may result in errors, if you want to upgrade the OS version, you should use <code class="docutils literal notranslate"><span class="pre">swupd_args</span></code> instead.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">swupd_args</span></code> specifies <a class="reference external" href="https://github.com/clearlinux/swupd-client/blob/master/docs/swupd.1.rst#options">swupd update</a> flags passed to the update during build.</p></li>
</ul>
<blockquote>
<div><p>NOTE: An empty <code class="docutils literal notranslate"><span class="pre">swupd_args</span></code> will default to 32690. Consider this when building as an OS upgrade won’t be performed. If you’d like to upgrade the OS version, you can either do it manually inside a running container or add <code class="docutils literal notranslate"><span class="pre">swupd_args=&quot;&lt;desired</span> <span class="pre">version&gt;&quot;</span></code> to the build command. The latest validated version is 32690, using a different one might result in unexpected errors.</p>
</div></blockquote>
</div>
<hr class="docutils" />
<div class="section" id="using-the-intel-openvino-model-optimizer">
<h2>Using the Intel® OpenVINO Model Optimizer<a class="headerlink" href="#using-the-intel-openvino-model-optimizer" title="Permalink to this headline">¶</a></h2>
<p>The Intel OpenVINO toolkit has two primary tools for Deep Learning, the inference engine and the model optimzer. The inference engine is integrated into the Deep Learning Reference Stack, however the model optimizer is better used separately post training before inference begins. This tutorial will explain how to use the model optimizer by going through a test case with a pre-trained TensorFlow model.</p>
<p>This guide will use resources found in the OpenVino Toolkit documentation. Original documentation is here:</p>
<p><a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">Converting a TensorFlow Model</a> - Where to download supported topologies</p>
<p><a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">Converting TensorFlow Object Detection API Models</a> - Instructions on converting specific models</p>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>In this tutorial, you will:</p>
<ol class="simple">
<li><p>Download a TensorFlow model</p></li>
<li><p>Clone the Model Optimizer</p></li>
<li><p>Install Prerequisites</p></li>
<li><p>Run the Model Optimizer</p></li>
</ol>
</div>
<div class="section" id="requirements">
<h3>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h3>
<p>This tutorial assumes development on a linux OS with a terminal dev environment. The tutorial was tested in Ubuntu 18.04.2.</p>
</div>
<div class="section" id="download-a-tensorflow-model">
<h3>Download a TensorFlow model<a class="headerlink" href="#download-a-tensorflow-model" title="Permalink to this headline">¶</a></h3>
<p>We will be using an OpenVINO supported topology with the Model Optimizer. We will use a TensorFlow Inception V2 frozen model.</p>
<p>Navigate to the <a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">OpenVINO TensorFlow Model page.</a> Then scroll down to the second section titled “Supported Frozen Topologies from TensorFlow Object Detection Models Zoo” and download “SSD Inception V2 COCO.”</p>
<p>Unpack the file into your chosen working directory. For example, if the tar file is in your Downloads folder and you have navigated to the directory you want to extract it into, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar</span> <span class="o">-</span><span class="n">xvf</span> <span class="o">~/</span><span class="n">Downloads</span><span class="o">/</span><span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
</div>
<div class="section" id="clone-the-model-optimizer">
<h3>Clone the Model Optimizer<a class="headerlink" href="#clone-the-model-optimizer" title="Permalink to this headline">¶</a></h3>
<p>Next we need the model optimizer directory, named dldt, found <a class="reference external" href="https://github.com/opencv/dldt">here.</a> This guide will assume the parent directory is on the same level as the model directory, ie:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">.</span>
<span class="o">+--</span><span class="n">Working_Directory</span>
   <span class="o">+--</span> <span class="n">ssd_inception_v2_coco_2018_01_28</span>
   <span class="o">+--</span> <span class="n">dldt</span>
</pre></div>
</div>
<p>From inside the working directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">opencv</span><span class="o">/</span><span class="n">dldt</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
<p>If you explore the dldt directory, you’ll see both the inference engine and the model optimizer. We are only concerned with the model optimizer. Navigating into the model optimizer folder you’ll find several python scripts and text files. These are the scripts you call to run the model optimizer.</p>
</div>
<div class="section" id="install-prerequisites">
<h3>Install Prerequisites<a class="headerlink" href="#install-prerequisites" title="Permalink to this headline">¶</a></h3>
<p>Install the Python packages required to run the model optimizer by running the script dldt/model-optimizer/install_prerequisites/install_prerequisites_tf.sh.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">dldt</span><span class="o">/</span><span class="n">model</span><span class="o">-</span><span class="n">optimizer</span><span class="o">/</span><span class="n">install_prerequisites</span><span class="o">/</span>
<span class="o">./</span><span class="n">install_prerequisites_tf</span><span class="o">.</span><span class="n">sh</span>
<span class="n">cd</span> <span class="o">../../..</span>
</pre></div>
</div>
</div>
<div class="section" id="run-the-model-optimizer">
<h3>Run the Model Optimizer<a class="headerlink" href="#run-the-model-optimizer" title="Permalink to this headline">¶</a></h3>
<p>Running the model optimizer is as simple as calling the appropriate script, however there are many configuration options that are explained <a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">here.</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">dldt</span><span class="o">/</span><span class="n">model</span><span class="o">-</span><span class="n">optimizer</span><span class="o">/</span><span class="n">mo_tf</span><span class="o">.</span><span class="n">py</span> \
<span class="o">--</span><span class="n">input_model</span><span class="o">=</span><span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">/</span><span class="n">frozen_inference_graph</span><span class="o">.</span><span class="n">pb</span> \
<span class="o">--</span><span class="n">tensorflow_use_custom_operations_config</span> <span class="n">dldt</span><span class="o">/</span><span class="n">model</span><span class="o">-</span><span class="n">optimizer</span><span class="o">/</span><span class="n">extensions</span><span class="o">/</span><span class="n">front</span><span class="o">/</span><span class="n">tf</span><span class="o">/</span><span class="n">ssd_v2_support</span><span class="o">.</span><span class="n">json</span> \
<span class="o">--</span><span class="n">tensorflow_object_detection_api_pipeline_config</span> <span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">/</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span> \
<span class="o">--</span><span class="n">reverse_input_channels</span>
</pre></div>
</div>
<p>You should now see three files in your working directory, frozen_inference_graph.bin, frozen_inference_graph.mapping, and frozen_inference_graph.xml. These are your new models in the Intermediate Representation (IR) format and they are ready for use in the OpenVINO Inference Engine.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="using-the-openvino-inference-engine">
<h2>Using the OpenVino Inference Engine<a class="headerlink" href="#using-the-openvino-inference-engine" title="Permalink to this headline">¶</a></h2>
<p>Basic example on how to run the inference engine on your local machine</p>
<div class="section" id="starting-the-model-server">
<h3>Starting the Model Server<a class="headerlink" href="#starting-the-model-server" title="Permalink to this headline">¶</a></h3>
<p>The process is similar to how we start <code class="docutils literal notranslate"><span class="pre">Jupter</span> <span class="pre">notebooks</span></code> on our containers</p>
<p>Run this command to spin up a OpenVino model fetched from GCP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run -p <span class="m">8000</span>:8000 stacks-tensorflow-mkl:latest bash -c <span class="s2">&quot;. /workspace/scripts/serve.sh &amp;&amp; ie_serving model --model_name resnet --model_path gs://public-artifacts/intelai_public_models/resnet_50_i8 --port 8000&quot;</span>
</pre></div>
</div>
<p>Once the server is setup, use a <code class="docutils literal notranslate"><span class="pre">grpc</span></code> client to communicate with served model, here is an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">IntelAI</span><span class="o">/</span><span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">r</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span><span class="o">/</span><span class="n">client_requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">r</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span><span class="o">/</span><span class="n">client_requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">cat</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span><span class="o">/</span><span class="n">client_requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">cd</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span>

<span class="n">python</span> <span class="n">jpeg_classification</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">images_list</span> <span class="n">input_images</span><span class="o">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">grpc_address</span> <span class="n">localhost</span> <span class="o">--</span><span class="n">grpc_port</span> <span class="mi">8000</span> <span class="o">--</span><span class="n">input_name</span> <span class="n">data</span> <span class="o">--</span><span class="n">output_name</span> <span class="n">prob</span> <span class="o">--</span><span class="n">size</span> <span class="mi">224</span> <span class="o">--</span><span class="n">model_name</span> <span class="n">resnet</span>
</pre></div>
</div>
<p>You should get an output like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="n">processing</span><span class="p">:</span>
	<span class="n">Model</span> <span class="n">name</span><span class="p">:</span> <span class="n">resnet</span>
	<span class="n">Images</span> <span class="nb">list</span> <span class="n">file</span><span class="p">:</span> <span class="n">input_images</span><span class="o">.</span><span class="n">txt</span>
<span class="n">images</span><span class="o">/</span><span class="n">airliner</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">97.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">10.35</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">404</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">404</span>
<span class="n">images</span><span class="o">/</span><span class="n">arctic</span><span class="o">-</span><span class="n">fox</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">16.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">63.89</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">279</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">279</span>
<span class="n">images</span><span class="o">/</span><span class="n">bee</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">14.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">69.82</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">309</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">309</span>
<span class="n">images</span><span class="o">/</span><span class="n">golden_retriever</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">13.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">75.22</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">207</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">207</span>
<span class="n">images</span><span class="o">/</span><span class="n">gorilla</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">11.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">87.24</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">366</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">366</span>
<span class="n">images</span><span class="o">/</span><span class="n">magnetic_compass</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">247.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">11.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">91.07</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">635</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">635</span>
<span class="n">images</span><span class="o">/</span><span class="n">peacock</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">9.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">110.1</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">84</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">84</span>
<span class="n">images</span><span class="o">/</span><span class="n">pelican</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">10.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">103.63</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">144</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">144</span>
<span class="n">images</span><span class="o">/</span><span class="n">snail</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">248.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">10.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">104.33</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">113</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">113</span>
<span class="n">images</span><span class="o">/</span><span class="n">zebra</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">12.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">83.04</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">340</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">340</span>
<span class="n">Overall</span> <span class="n">accuracy</span><span class="o">=</span> <span class="mf">100.0</span> <span class="o">%</span>
<span class="n">Average</span> <span class="n">latency</span><span class="o">=</span> <span class="mf">19.8</span> <span class="n">ms</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="licenses/README.html" class="btn btn-neutral float-right" title="Additional details on licenses" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../../pytorch/oss/licenses/README.html" class="btn btn-neutral float-left" title="Additional details on licenses" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>