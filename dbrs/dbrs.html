

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Database Reference Stack Guide &mdash; System Stacks for Linux* OS  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/semantic-ui-2.4.1/segment.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/semantic-ui-2.4.1/menu.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/semantic-ui-2.4.1/tab.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx_tabs/tabs.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/sphinx_tabs/semantic-ui-2.4.1/tab.min.js"></script>
        <script src="../_static/sphinx_tabs/tabs.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Database Reference Stack with Redis" href="clearlinux/redis/README.html" />
    <link rel="prev" title="Database Reference Stack Terms of Use" href="terms_of_use.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> System Stacks for Linux* OS
          

          
            
            <img src="../_static/stacks_logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html">System Stacks for Linux* OS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../README.html#contributing">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../README.html#security-issues">Security Issues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../README.html#mailing-list">Mailing List</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../dlrs/index.html">Deep Learning Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../dlrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/README.html">Deep Learning Reference Stack README</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html">Deep Learning Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html#the-deep-learning-reference-stack-release">The Deep Learning Reference Stack Release</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html#working-with-the-deep-learning-reference-stack">Working with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html#performance-tuning-configurations">Performance tuning configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html#contributing-to-the-deep-learning-reference-stack">Contributing to the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/terms_of_use.html">Deep Learning Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dlrs/index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/dlrs.html">Deep Learning Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#tensorflow-single-and-multi-node-benchmarks">TensorFlow single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#pytorch-single-and-multi-node-benchmarks">PyTorch single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#tensorflow-training-tfjob-with-kubeflow-and-dlrs">TensorFlow Training (TFJob) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#pytorch-training-pytorch-job-with-kubeflow-and-dlrs">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#working-with-horovod-and-openmpi">Working with Horovod* and OpenMPI*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#using-transformers-for-natural-language-processing">Using Transformers* for Natural Language Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#using-the-openvino-model-optimizer">Using the OpenVINO™ Model Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#using-the-openvino-toolkit-inference-engine">Using the OpenVINO™ toolkit Inference Engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#using-seldon-and-openvino-model-server-with-the-deep-learning-reference-stack">Using Seldon and OpenVINO™ model server with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#use-jupyter-notebook">Use Jupyter Notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#uninstallation">Uninstallation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#compiling-aixprt-with-openmp-on-dlrs">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/dlrs.html#related-topics">Related topics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dlrs/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/clearlinux/README.html">Deep Learning Reference Stack containers based on Clear Linux OS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/clearlinux/ml-compiler/README.html">System Stacks Deep Learning Compiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/ml-compiler/README.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/ml-compiler/README.html#build-args">Build ARGs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/index.html#pytorch-versions">PyTorch versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/pytorch/mkl/README.html">Deep Learning Reference Stack with Pytorch and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/pytorch/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/pytorch/oss/README.html">Deep Learning Reference Stack with Pytorch and OpenBLAS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/pytorch/oss/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../dlrs/index.html#tensorflow-versions">TensorFlow versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow/mkl/README.html">Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow/mkl/scripts/README.html">Deep Learning Reference Stack Scripts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow/oss/README.html">Deep Learning Reference Stack with Tensorflow and Optimized Eigen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow/oss/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow_2/mkl/README.html">Deep Learning Reference Stack with TensorFlow 2.0 and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow_2/mkl/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dlrs/clearlinux/tensorflow_2/mkl/scripts/README.html">Deep Learning Reference Stack Scripts</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../dars/index.html">Data Analytics Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../dars/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dars/clearlinux/releasenote.html">Data Analytics Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/releasenote.html#stack-features">Stack Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/releasenote.html#the-data-analytics-reference-stack-with-mkl">The Data Analytics Reference Stack with MKL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/releasenote.html#the-data-analytics-reference-stack-with-openblas">The Data Analytics Reference Stack with OpenBLAS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../dars/clearlinux/releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dars/clearlinux/releasenote.html#working-with-the-data-analytics-reference-stack">Working with the Data Analytics Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dars/clearlinux/releasenote.html#contributing-to-the-database-reference-stack">Contributing to the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dars/clearlinux/releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dars/terms_of_use.html">Data Analytics Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dars/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dars/dars.html">Data Analytics Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dars/dars.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/dars.html#using-the-docker-images">Using the Docker images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/dars.html#using-apache-spark-in-dars">Using Apache Spark* in DARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/dars.html#using-apache-hadoop-in-dars">Using Apache Hadoop in DARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/dars.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/dars.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../dars/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../dars/clearlinux/README.html">Data Analytics Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dars/index.html#openblas-versions">OpenBLAS versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html">Data Analytics Reference Stack with OpenBLAS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#java-requirements">Java Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#single-node-hadoop-cluster-setup">Single Node Hadoop Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#inside-the-running-container-we-need-to-edit-hadoop-configuration-files-as-follows">Inside the running container we need to edit hadoop configuration files as follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#start-hadoop-daemons">Start Hadoop daemons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#single-node-spark-cluster-setup">Single Node Spark Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#run-the-pi-calculator-example-on-spark-shell">Run the Pi Calculator Example on spark-shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#run-the-pi-calculator-example-on-pyspark">Run the Pi Calculator Example on pyspark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#kubernetes-installation">Kubernetes installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/README.html#faq"><strong>FAQ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/openblas/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../dars/index.html#mkl-versions">MKL versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html">Data Analytics Reference Stack with Intel® MKL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#java-requirements">Java Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#single-node-hadoop-cluster-setup">Single Node Hadoop Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#inside-the-running-container-we-need-to-edit-hadoop-configuration-files-as-follows">Inside the running container we need to edit hadoop configuration files as follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#start-hadoop-daemons">Start Hadoop daemons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#single-node-spark-cluster-setup">Single Node Spark Cluster Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#run-the-pi-calculator-example-on-spark-shell">Run the Pi Calculator Example on spark-shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#run-the-pi-calculator-example-on-pyspark">Run the Pi Calculator Example on pyspark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#deploy-dars-on-kubernetes">Deploy DARS on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#kubernetes-installation">Kubernetes installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/README.html#faq"><strong>FAQ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../dars/clearlinux/mkl/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Database Reference Stack</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="README.html">Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="releasenote.html">Database Reference Stack Release Note</a></li>
<li class="toctree-l3"><a class="reference internal" href="releasenote.html#the-database-reference-stack-releases">The Database Reference Stack Releases</a><ul>
<li class="toctree-l4"><a class="reference internal" href="releasenote.html#the-database-reference-stack-with-cassandra">The Database Reference Stack with Cassandra</a></li>
<li class="toctree-l4"><a class="reference internal" href="releasenote.html#the-database-reference-stack-with-redis">The Database Reference Stack with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="releasenote.html#the-database-reference-stack-with-memcached">The Database Reference Stack with Memcached</a></li>
<li class="toctree-l4"><a class="reference internal" href="releasenote.html#how-to-get-the-database-reference-stack">How to get the Database Reference Stack</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="releasenote.html#licensing">Licensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="releasenote.html#working-with-the-database-reference-stack">Working with the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="releasenote.html#contributing-to-the-database-reference-stack">Contributing to the Database Reference Stack</a></li>
<li class="toctree-l3"><a class="reference internal" href="releasenote.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="terms_of_use.html">Database Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#guide">Guide</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Database Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hardware-requirements">Hardware Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="#firmware-configuration">Firmware configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hardware-configuration">Hardware Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-dbrs-with-apache-cassandra">Running DBRS with Apache Cassandra*</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deploy-an-apache-cassandra-pmem-cluster-on-kubernetes">Deploy An Apache Cassandra-PMEM cluster on Kubernetes*</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-dbrs-with-redis">Running DBRS with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-dbrs-with-memcached">Running DBRS with Memcached</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="clearlinux/redis/README.html">Database Reference Stack with Redis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/redis/README.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/redis/README.html#clone-the-repository">Clone the repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/redis/README.html#run-dbrs-redis-as-a-standalone-container">Run DBRS Redis as a standalone container</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/redis/README.html#deploy-dbrs-redis-cluster-on-kubernetes">Deploy DBRS Redis cluster on Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="clearlinux/redis/licenses/README.html">Additional details on licenses</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#apache-cassandra-versions">Apache Cassandra* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/cassandra/README.html">Database Reference Stack with Cassandra</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/cassandra/cassandra-pmem-helm/files/conf/README.html">Configuration files</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/cassandra/cassandra-pmem-helm/files/testProfiles/README.html">Test profiles</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/cassandra/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="index.html#memcached-versions">memcached versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/memcached/README.html">Memcached DBRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/memcached/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="index.html#redis-versions">REDIS versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/redis/README.html">Database Reference Stack with Redis</a></li>
<li class="toctree-l4"><a class="reference internal" href="clearlinux/redis/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#centos-based-containers">CentOS based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="centos8/memcached/README.html">Memcached DBRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="centos8/memcached/README.html#build-dbrs-memcached-image">Build DBRS Memcached image</a></li>
<li class="toctree-l4"><a class="reference internal" href="centos8/memcached/README.html#run-dbrs-memcached-as-a-standalone-container">Run DBRS Memcached as a standalone container</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="centos8/memcached/licenses/README.html">Additional details on licenses</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mers/index.html">Media Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../mers/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../mers/README.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../mers/README.html#source-code">Source Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/README.html#supported-platforms-and-media-codecs">Supported Platforms and Media Codecs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../mers/releasenotes.html">Media Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#the-media-reference-stack">The Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#the-media-reference-stack-licenses">The Media Reference Stack licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#disclaimer">Disclaimer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#source-code">Source code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#contributing-to-the-media-reference-stack">Contributing to the Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/releasenotes.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../mers/terms_of_use.html">Media Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mers/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../mers/mers.html">Media Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../mers/mers.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/mers.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/mers.html#get-the-pre-built-mers-container-image">Get the pre-built MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/mers.html#build-the-mers-container-image-from-source">Build the MeRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/mers.html#use-the-mers-container-image">Use the MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/mers.html#add-aom-support">Add AOM support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mers/index.html#clear-linux-based-containers">Clear Linux based containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../mers/clearlinux/INSTALL.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../mers/clearlinux/INSTALL.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/clearlinux/INSTALL.html#pulling-from-docker-hub">Pulling from Docker Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/clearlinux/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mers/clearlinux/INSTALL.html#run-examples">Run examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../hpcrs/index.html">High Performance Computing Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../hpcrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../hpcrs/README.html">High Performance Compute Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#stack-features">Stack features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#get-the-pre-built-hpcrs-container-image">Get the pre-built HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#build-the-hpcrs-container-image-from-source">Build the HPCRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#use-the-hpcrs-container-image">Use the HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#convert-the-hpcrs-image-to-a-singularity-image">Convert the HPCRS image to a Singularity image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/README.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../hpcrs/NEWS.html">Release notes for HPCRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/NEWS.html#release-v0-1-0">Release <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code> :</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../hpcrs/terms_of_use.html">High Performance Computing Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../hpcrs/index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../hpcrs/d2s/Readme.html">d2s - A wrapper used to convert Docker images to Singularity images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/d2s/Readme.html#version-compatibility">Version compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/d2s/Readme.html#install-singularity">Install Singularity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/d2s/Readme.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/d2s/Readme.html#download-compile-singularity">Download &amp; Compile <em>Singularity</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../hpcrs/d2s/Readme.html#source-bash-completion-file-optional">Source bash completion file (Optional)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../hpcrs/docs/FAQ.html">HPCRS Frequently Asked Questions (FAQ)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks">Project GitHub repository</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">System Stacks for Linux* OS</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Database Reference Stack</a> &raquo;</li>
        
      <li>Database Reference Stack Guide</li>
    
    

  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="database-reference-stack-guide">
<span id="dbrs-guide"></span><h1>Database Reference Stack Guide<a class="headerlink" href="#database-reference-stack-guide" title="Permalink to this headline">¶</a></h1>
<p>This guide describes the hardware and installation requirements for using the
<abbr title="Database Reference Stack">DBRS</abbr>, along with getting started configuration examples, using Clear Linux OS| as the host system.</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id3">Overview</a></p></li>
<li><p><a class="reference internal" href="#releases" id="id4">Releases</a></p></li>
<li><p><a class="reference internal" href="#hardware-requirements" id="id5">Hardware Requirements</a></p></li>
<li><p><a class="reference internal" href="#firmware-configuration" id="id6">Firmware configuration</a></p></li>
<li><p><a class="reference internal" href="#hardware-configuration" id="id7">Hardware Configuration</a></p></li>
<li><p><a class="reference internal" href="#running-dbrs-with-apache-cassandra" id="id8">Running DBRS with Apache Cassandra*</a></p></li>
<li><p><a class="reference internal" href="#deploy-an-apache-cassandra-pmem-cluster-on-kubernetes" id="id9">Deploy An Apache Cassandra-PMEM cluster on Kubernetes*</a></p></li>
<li><p><a class="reference internal" href="#running-dbrs-with-redis" id="id10">Running DBRS with Redis</a></p></li>
<li><p><a class="reference internal" href="#running-dbrs-with-memcached" id="id11">Running DBRS with Memcached</a></p></li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id3">Overview</a><a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The Database Reference Stack is integrated, highly-performant, open source,
and optimized for 2nd generation Intel® Xeon® Scalable Processors and Intel®
Optane™ persistent memory. This open source community release is part of
an effort to ensure developers have easy access to the features and
functionality of Intel Platforms.</p>
<div class="section" id="stack-features">
<h3>Stack Features<a class="headerlink" href="#stack-features" title="Permalink to this headline">¶</a></h3>
<p>Current supported  database applications are Apache Cassandra* and Redis*, which
have been enabled for <a class="reference external" href="https://www.intel.com/content/www/us/en/architecture-and-technology/optane-technology/optane-for-data-centers.html">Intel Optane PMM</a>.</p>
<p>DBRS with Apache Cassandra can be deployed as a standalone container or inside a
Kubernetes* cluster.</p>
<p>The Redis stack application is enabled for a multinode Kubernetes
environment, using AEP PMem DIMM in fsdax mode for storage.</p>
</div>
</div>
<div class="section" id="releases">
<h2><a class="toc-backref" href="#id4">Releases</a><a class="headerlink" href="#releases" title="Permalink to this headline">¶</a></h2>
<p>Refer to the <a class="reference external" href="https://clearlinux.org/stacks/database-reference">Database Reference Stack website</a> for information and download links for the different versions and offerings of the stack.</p>
<p>The release announcement for each release provides more detail about the stack features, as well as benchmark results.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://clearlinux.org/blogs-news/database-reference-stack-dbrs-v2-now-available">DBRS V2.0</a> release announcement.</p></li>
<li><p><a class="reference external" href="https://clearlinux.org/news-blogs/database-reference-stack-dbrs-v10-now-available">DBRS V1.0</a> release announcement.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Database Reference Stack is a collective work, and each piece
of software within the work has its own license.  Please see the
<a class="reference external" href="https://clearlinux.org/stacks/database/terms-of-use">DBRS Terms of Use</a> for more details about licensing and usage of the Database Reference Stack.</p>
</div>
</div>
<div class="section" id="hardware-requirements">
<h2><a class="toc-backref" href="#id5">Hardware Requirements</a><a class="headerlink" href="#hardware-requirements" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Intel® Xeon Scalable Platform with Intel® C620 chipset series</p></li>
<li><p>2nd Gen Intel® Xeon Scalable processor CPU (Intel® Optane™ PMM-enabled stepping) Provides cache &amp; memory control.  Intel® Optane™  PMem works only on systems powered by 2nd Generation Intel® Xeon® Platinum or Gold processors.</p></li>
<li><p>BIOS with Reference Code</p></li>
<li><p>Intel®Optane™ PMem</p></li>
</ul>
<div class="section" id="hardware-configuration-used-in-stacks-development">
<h3>Hardware configuration used in stacks development<a class="headerlink" href="#hardware-configuration-used-in-stacks-development" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Intel® Server System R2208WFTZSR</p></li>
<li><p>BIOS with Reference Code
* BIOS ID: SE5C620.86B.0D.01.0438.032620191658
* BMC Firmware: 1.94.6b42b91d
* Intel® Optane™ PMemFirmware: 1.2.0.5310</p></li>
<li><p>2x Intel® Xeon Platinum 8268 Processor</p></li>
<li><p>Intel® SSD DC S5600 Series 960GB 2.5in SATA Drive</p></li>
<li><p>64 GB RAM - Distributed in 4x 16 GB DDR4 DIMM’s</p></li>
<li><p>2x Intel® Optane™ PMem 256GB Module</p></li>
<li><p>1-1-1 Layout 8 Optane™ : 1 RAM ratio</p></li>
</ul>
<table class="colwidths-given docutils align-default" id="id2">
<caption><span class="caption-text"><strong>Table 1. IMC</strong></span><a class="headerlink" href="#id2" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Channel 2</p></th>
<th class="head"><p>Channel 2</p></th>
<th class="head"><p>Channel 1</p></th>
<th class="head"><p>Channel 1</p></th>
<th class="head"><p>Channel 0</p></th>
<th class="head"><p>Channel 0</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Slot 1</p></td>
<td><p>Slot 0</p></td>
<td><p>Slot 1</p></td>
<td><p>Slot 0</p></td>
<td><p>Slot 1</p></td>
<td><p>Slot 0</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>256 GB DCPMM</p></td>
<td></td>
<td><p>16 GB DRAM</p></td>
<td></td>
<td><p>16 GB DRAM</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="firmware-configuration">
<h2><a class="toc-backref" href="#id6">Firmware configuration</a><a class="headerlink" href="#firmware-configuration" title="Permalink to this headline">¶</a></h2>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>When updating DCPMM Firmware, all DCPMM parts must be in the same mode (you cannot mix 1LM and 2LM parts).</p>
</div>
<p>The latest firmware download for the Intel® Server System S2600WF Family is available at the <a class="reference external" href="https://downloadcenter.intel.com/download/28695/Intel-Server-Board-S2600WF-Family-BIOS-and-Firmware-Update-Package-for-UEFI">Intel Download Center</a></p>
<div class="section" id="firmware-update-steps">
<h3>Firmware Update Steps<a class="headerlink" href="#firmware-update-steps" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>Unzip the contents of the update package and copy all files to the root directory of a removable media (USB flash drive).</p></li>
<li><p>Insert the USB flash drive to any available USB port on the system to be updated.</p></li>
<li><p>Boot to EFI shell.</p></li>
<li><p>Input “fsx(x:0,1,…):” to enter into your usb disk</p></li>
<li><p>Run “startup.nsh”</p></li>
<li><p>After update BMC firmware, system BIOS, ME firmware,FD, FRUSDR, system will reboot automatically.</p></li>
</ol>
<p>If Intel® Optane™ PMem is installed, run startup.nsh a second time after the first reboot to upgrade Intel® Optane™ PMem Firmware:</p>
<ul class="simple">
<li><p>Boot to EFI shell.</p></li>
<li><p>Input “fsx(x:0,1,…):” to enter into your usb disk</p></li>
<li><p>Run “startup.nsh” again to update the corresponding AEP FW.</p></li>
</ul>
</div>
</div>
<div class="section" id="hardware-configuration">
<span id="dbrs-hardware-configuration"></span><h2><a class="toc-backref" href="#id7">Hardware Configuration</a><a class="headerlink" href="#hardware-configuration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="online-resources">
<h3>Online Resources<a class="headerlink" href="#online-resources" title="Permalink to this headline">¶</a></h3>
<p>Before going through the configuration steps, we strongly recommend visiting the following resources and wikis to have a broader understanding of what is being done</p>
<ul class="simple">
<li><p><a class="reference external" href="https://software.intel.com/en-us/articles/quick-start-guide-configure-intel-optane-dc-persistent-memory-on-linux">Quick Start Guide</a> Configure Intel® Optane™ PMem Modules on Linux</p></li>
<li><p><a class="reference external" href="https://docs.pmem.io/ndctl-user-guide/managing-nvdimms">Managing NVDIMMs</a></p></li>
<li><p><a class="reference external" href="https://software.intel.com/en-us/articles/configure-manage-and-profile-intel-optane-dc-persistent-memory-modules">Configure, Manage, and Profile</a> Intel® Optane™ PMem Modules</p></li>
</ul>
</div>
<div class="section" id="optane-dimm-configuration">
<h3>Optane™ DIMM Configuration<a class="headerlink" href="#optane-dimm-configuration" title="Permalink to this headline">¶</a></h3>
<p>The PMem DIMMs can be configured in devdax or fsdax mode. The use case to enable database stack on a kubernetes environment currently only support fsdax mode.</p>
</div>
<div class="section" id="configuration-steps">
<h3>Configuration Steps<a class="headerlink" href="#configuration-steps" title="Permalink to this headline">¶</a></h3>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Run the following steps with root privileges (sudo) as shown in the examples</p>
</div>
<ol class="arabic">
<li><p>To configure Optane™ DIMMs for App direct mode run this command</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ipmctl create -goal <span class="nv">PersistentMemoryType</span><span class="o">=</span>AppDirect
</pre></div>
</div>
</li>
<li><p>Verify the Optane™ Configuration by showing the defined region, then reboot the system for your changes to take effect</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ipmctl show -region
</pre></div>
</div>
</li>
<li><p>Next, list the defined namespaces for the pmem devices in the system. If they are not defined, create them as shown in the following step.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ndctl list -N
</pre></div>
</div>
</li>
<li><p>Create namespaces based on the regions and set mode as fsdax  – use the names of the regions listed in previous step as the –-region parameter (default is region0 and region1; one for each CPU socket)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ndctl create-namespace --region<span class="o">=</span>region0 --mode<span class="o">=</span>fsdax
sudo ndctl create-namespace --region<span class="o">=</span>region1 --mode<span class="o">=</span>fsdax
</pre></div>
</div>
</li>
<li><p>Create the filesystem and mount it. We are using /mnt/dax{#} as a convention in this guide to mount our devices</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo mkfs.ext4 /dev/pmem0
sudo mount -o dax /dev/pmem0 /mnt/dax0
sudo mkfs.ext4 /dev/pmem1
sudo mount -o dax /dev/pmem1 /mnt/dax1
</pre></div>
</div>
</li>
</ol>
</div>
</div>
<div class="section" id="running-dbrs-with-apache-cassandra">
<h2><a class="toc-backref" href="#id8">Running DBRS with Apache Cassandra*</a><a class="headerlink" href="#running-dbrs-with-apache-cassandra" title="Permalink to this headline">¶</a></h2>
<p>DBRS with Apache Cassandra can be deployed as a standalone container or inside
Kubernetes*. Instructions for both cases is included here. Note that you can
use the released <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dbrs-cassandra">Docker image with Apache Cassandra</a> (Docker* examples below).
These instructions provide a baseline for creating your own container image.
If you are using the released image, skip this section.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>At the initial release of DBRS, Apache Cassandra is considered to be Engineering Preview release quality and may not be suitable for production release.  Please take this into consideration when planning your project.</p>
</div>
<div class="section" id="build-the-dbrs-with-apache-cassandra-container">
<h3>Build the DBRS with Apache Cassandra container<a class="headerlink" href="#build-the-dbrs-with-apache-cassandra-container" title="Permalink to this headline">¶</a></h3>
<p>To build the container with Apache Cassandra, you must build cassandra-pmem, and then build the container using the <strong class="command">docker build</strong> command. We are using Clear Linux OS as our container host as well as the OS in the container.</p>
</div>
<div class="section" id="build-cassandra-pmem">
<h3>Build cassandra-pmem<a class="headerlink" href="#build-cassandra-pmem" title="Permalink to this headline">¶</a></h3>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>At the initial release of DBRS, the pmem-csi driver is considered to be Engineering Preview release quality and may not be suitable for production release.  Please take this into consideration when planning your project.</p>
</div>
<p>In the <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dbrs">DBRS github repository</a>, there is a file called <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dbrs/cassandra/scripts/">build-cassandra-pmem.sh</a>, which handles all the requirements for compiling cassandra-pmem for Dockerfile usage. The dependencies for this build can be installed with <strong class="command">swupd</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo swupd bundle-add c-basic java-basic devpkg-pmdk pmdk
</pre></div>
</div>
<p>Once installed, we run the script</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./build-cassandra-pmem.sh
</pre></div>
</div>
<p>At the completion of the build you will have a file called <code class="file docutils literal notranslate"><span class="pre">cassandra-pmem-build.tar.gz</span></code>. Place this file in the same directory with the Dockerfile  to build the Docker image.</p>
</div>
<div class="section" id="build-the-docker-container">
<h3>Build the Docker container<a class="headerlink" href="#build-the-docker-container" title="Permalink to this headline">¶</a></h3>
<p>To build the Docker image, run the Dockerfile in the same directory with the <code class="file docutils literal notranslate"><span class="pre">cassandra-pmem-build.tar.gz</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker build --force-rm --no-cache -f Dockerfile -t <span class="nv">$build_image_name</span> .
</pre></div>
</div>
<p>Once it completes, the Docker image is ready to be used.</p>
</div>
<div class="section" id="deploy-apache-cassandra-pmem-as-a-standalone-container">
<h3>Deploy Apache Cassandra PMEM as a standalone container<a class="headerlink" href="#deploy-apache-cassandra-pmem-as-a-standalone-container" title="Permalink to this headline">¶</a></h3>
<div class="section" id="requirements">
<h4>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h4>
<p>To deploy Apache Cassandra PMEM, you must meet the following requirements</p>
<ul class="simple">
<li><p>PMEM memory must be configured in <cite>devdax</cite> or <cite>fsdax</cite>    mode. The container image is able to handle both modes and depending on the PMEM mode, the mount points inside the container must be different.</p></li>
<li><p>In order to make available <cite>devdax</cite> pmem devices inside the container you must use the <cite>–device</cite> directive. Internally the container always uses <strong class="command">/dev/dax0.0</strong>, so the mapping should be: <strong class="command">--device=/dev/&lt;host-device&gt;:/dev/dax0.0</strong></p></li>
<li><p>In a similar fashion for <cite>fsdax</cite> we need the device to be mapped to <strong class="command">/mnt/pmem</strong> inside the container: <strong class="command">--mount type=bind,source=&lt;source-mount-point&gt;,target=/mnt/pmem</strong></p></li>
</ul>
</div>
<div class="section" id="preparing-pmem-for-container-use">
<h4>Preparing PMEM for container use<a class="headerlink" href="#preparing-pmem-for-container-use" title="Permalink to this headline">¶</a></h4>
<p>The cassandra-pmem image is capable of using both <cite>fsdax</cite>   and <cite>devdax</cite>, the necessary steps to configure the PMEM to work with cassandra are documented here.</p>
<div class="sphinx-tabs docutils container">
<div class="ui top attached tabular menu sphinx-menu docutils container">
<div class="active item sphinx-data-tab-ZGV2ZGF4 docutils container">
<div class="docutils container">
<p>devdax</p>
</div>
</div>
<div class="item sphinx-data-tab-ZnNkYXg= docutils container">
<div class="docutils container">
<p>fsdax</p>
</div>
</div>
</div>
<div class="ui bottom attached sphinx-tab tab segment sphinx-data-tab-ZGV2ZGF4 active docutils container">
<p>We need to verify the device we want to use is in <cite>devdax</cite> mode</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ndctl create-namespace -fe namespace0.0  --mode<span class="o">=</span>devdax
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">  &quot;dev&quot;:&quot;namespace0.0&quot;,</span>
<span class="go">  &quot;mode&quot;:&quot;devdax&quot;,</span>
<span class="go">  &quot;map&quot;:&quot;dev&quot;,</span>
<span class="go">  &quot;size&quot;:&quot;3.94 GiB (4.23 GB)&quot;,</span>
<span class="go">  &quot;uuid&quot;:&quot;cb738cc7-711d-4578-bebf-1f7ba02ca169&quot;,</span>
<span class="go">  &quot;daxregion&quot;:{</span>
<span class="go">  &quot;id&quot;:0,</span>
<span class="go">  &quot;size&quot;:&quot;3.94 GiB (4.23 GB)&quot;,</span>
<span class="go">  &quot;align&quot;:2097152,</span>
<span class="go">  &quot;devices&quot;:[</span>
<span class="go">    {</span>
<span class="go">      &quot;chardev&quot;:&quot;dax0.0&quot;,</span>
<span class="go">      &quot;size&quot;:&quot;3.94 GiB (4.23 GB)&quot;</span>
<span class="go">    }</span>
<span class="go">  ]</span>
<span class="go"> },</span>
<span class="go"> &quot;align&quot;:2097152</span>
<span class="go">}</span>
</pre></div>
</div>
<p>If needed, we can reconfigure it using <strong class="command">ndctl create-namespace -fe &lt;namespace-name&gt;  --mode=devdax</strong>.</p>
<p>Before using a <cite>devdax</cite> device we need to clear the device:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo pmempool rm -vaf /dev/dax0.0
</pre></div>
</div>
<p>The <cite>jvm.options</cite> configuration for Apache Cassandra should look like the following:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">-Dpmem_path=/dev/dax0.0</span>
<span class="go">-Dpool_size=0</span>
</pre></div>
</div>
<p>Where
* pmem_path is the <cite>devdax</cite> device.
* pool_size=0 indicates to use the entire <cite>devdax</cite> device.</p>
<p>When using the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dbrs-cassandra">Docker image with Apache Cassandra</a>, the file <cite>jvm.options</cite> is automatically populated.</p>
</div>
<div class="ui bottom attached sphinx-tab tab segment sphinx-data-tab-ZnNkYXg= docutils container">
<p>Verify that the PMEM is in <cite>fsdax</cite> mode</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo ndctl list -u
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">  &quot;dev&quot;:&quot;namespace0.0&quot;,</span>
<span class="go">  &quot;mode&quot;:&quot;fsdax&quot;,</span>
<span class="go">  &quot;map&quot;:&quot;mem&quot;,</span>
<span class="go">  &quot;size&quot;:&quot;4.00 GiB (4.29 GB)&quot;,</span>
<span class="go">  &quot;sector_size&quot;:512,</span>
<span class="go">  &quot;blockdev&quot;:&quot;pmem0&quot;</span>
<span class="go">}</span>
</pre></div>
</div>
<p>If for some reason the device is not in <cite>fsdax</cite> mode you can reconfigure the namespace as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo <span class="sb">`</span>ndctl create-namespace -fe &lt;namespace-name&gt;  --mode<span class="o">=</span>fsdax<span class="sb">`</span>
</pre></div>
</div>
<p>Once the PMEM namespace is configured, you will see a device named <code class="file docutils literal notranslate"><span class="pre">/dev/pmem</span><em><span class="pre">0-9</span></em></code>. We will create a filesystem on that device. The filesystem could be <cite>ext4</cite> or <cite>xfs</cite>, for this example we are going to use <cite>ext4</cite>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo mkfs.ext4 /dev/pmem0
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">mke2fs 1.45.2 (27-May-2019)</span>
<span class="go">Creating filesystem with 1031680 4k blocks and 258048 inodes</span>
<span class="go">Filesystem UUID: 303c03f5-ac4e-4462-8bf9-bc6b0fae53fe</span>
<span class="go">Superblock backups stored on blocks:</span>
<span class="go">  32768, 98304, 163840, 229376, 294912, 819200, 884736</span>

<span class="go">Allocating group tables: done</span>
<span class="go">Writing inode tables: done</span>
<span class="go">Creating journal (16384 blocks): done</span>
<span class="go">Writing superblocks and filesystem accounting information: done</span>
</pre></div>
</div>
<p>Once the filesystem is created, we mount it with the dax option</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo mount /dev/pmem0 /mnt/pmem -o dax
</pre></div>
</div>
<p>When using <cite>fsdax</cite> mode cassandra-pmem creates a pool file on the pmem mountpoint, so the <cite>jvm.options</cite> configuration should look like the output below:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">-Dpmem_path=/mnt/pmem/cassandra_pool</span>
<span class="go">-Dpool_size=3221225472</span>
</pre></div>
</div>
<p>Where
* <cite>pmem_path</cite> is the path to the pool file, which should include the path itself and the file name
* <cite>pool_size</cite> is the size of the pool file in bytes. If you are using the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dbrs-cassandra">Docker image with Apache Cassandra</a> you can pass this value as an environment variable to the container runtime in Gb and the calculation is done automatically.</p>
<p>Is important to note that when creating the filesystem in the pmem device certain amount of space of the device is used by the filesystem metadata so the pool_size should be smaller than the total pmem namespace size.</p>
<p>When using the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dbrs-cassandra">Docker image with Apache Cassandra</a>, the file <cite>jvm.options</cite> is automatically populated with the environment variables <cite>CASSANDRA_PMEM_POOL_NAME</cite> and <cite>CASSANDRA_FSDAX_POOL_SIZE_GB</cite>.</p>
</div>
</div>
</div>
</div>
<div class="section" id="run-the-dbrs-container">
<h3>Run the DBRS Container<a class="headerlink" href="#run-the-dbrs-container" title="Permalink to this headline">¶</a></h3>
<p>Replace <cite>&lt;image-id&gt;</cite> in the following commands with the name of the image you are using.</p>
<div class="sphinx-tabs docutils container">
<div class="ui top attached tabular menu sphinx-menu docutils container">
<div class="active item sphinx-data-tab-ZGV2ZGF4 docutils container">
<div class="docutils container">
<p>devdax</p>
</div>
</div>
<div class="item sphinx-data-tab-ZnNkYXg= docutils container">
<div class="docutils container">
<p>fsdax</p>
</div>
</div>
</div>
<div class="ui bottom attached sphinx-tab tab segment sphinx-data-tab-ZGV2ZGF4 active docutils container">
<p>In <cite>devdax</cite> mode:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --device<span class="o">=</span>/&lt;devdax-device&gt;:/dev/dax0.0 --ulimit <span class="nv">nofile</span><span class="o">=</span><span class="m">262144</span>:262144 -p <span class="m">9042</span>:9042 -p <span class="m">7000</span>:7000 -it --name cassandra-test &lt;image-id&gt;
</pre></div>
</div>
</div>
<div class="ui bottom attached sphinx-tab tab segment sphinx-data-tab-ZnNkYXg= docutils container">
<p>In <cite>fsdax</cite> mode:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/&lt;fsdax-mountpoint&gt;,target<span class="o">=</span>/mnt/pmem  --ulimit <span class="nv">nofile</span><span class="o">=</span><span class="m">262144</span>:262144 -p <span class="m">9042</span>:9042 -p <span class="m">7000</span>:7000 -it -e <span class="s1">&#39;CASSANDRA_FSDAX_POOL_SIZE_GB=&lt;fsdax-pool-size-in-gb&gt;&#39;</span> --name cassandra-test &lt;image-id&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="container-configuration">
<h3>Container Configuration<a class="headerlink" href="#container-configuration" title="Permalink to this headline">¶</a></h3>
<div class="section" id="using-environment-variables">
<h4>Using environment variables<a class="headerlink" href="#using-environment-variables" title="Permalink to this headline">¶</a></h4>
<p>The container listens on the primary container IP address, but if required, some parameters can be provided as environment variables using <cite>–env</cite>.</p>
<ul class="simple">
<li><p><cite>CASSANDRA_CLUSTER_NAME</cite>  Cassandra cluster name, by default <cite>Cassandra Cluster</cite></p></li>
<li><p><cite>CASSANDRA_LISTEN_ADDRESS</cite>  Cassandra listen address</p></li>
<li><p><cite>CASSANDRA_RPC_ADDRESS</cite>  Cassandra RPC address</p></li>
<li><p><cite>CASSANDRA_SEED_ADDRESSES</cite>  A comma separated list of hosts in the cluster, if not provided, cassandra is going to run as a single node.</p></li>
<li><p><cite>CASSANDRA_SNITCH</cite>  The snitch type for the cluster, by default it is <cite>SimpleSnitch</cite>, for more complex snitches you can mount your own <cite>cassandra-rackdc.properties</cite> file.</p></li>
<li><p><cite>LOCAL_JMX</cite>  If set to <cite>no</cite> the JMX service will listen on all IP addresses, the default is <cite>yes</cite> and listens just on localhost 127.0.0.1</p></li>
<li><p><cite>JVM_OPTS</cite> When set you can pass additional arguments to the JVM for cassandra execution, for example for specifying memory heap sizes <cite>JVM_OPTS=-Xms16G -Xmx16G -Xmn12G</cite></p></li>
</ul>
<p>When using PMEM in <cite>fsdax</cite> mode, there are some parameters to control the allocation of memory:</p>
<ul class="simple">
<li><p><cite>CASSANDRA_FSDAX_POOL_SIZE_GB</cite>  The size of the fsdax pool in GB, if it is not specified the pool size is <cite>1</cite></p></li>
<li><p><cite>CASSANDRA_PMEM_POOL_NAME</cite>  The filename of the pool created in PMEM, by default <cite>cassandra_pool</cite></p></li>
</ul>
</div>
<div class="section" id="using-custom-files">
<h4>Using custom files<a class="headerlink" href="#using-custom-files" title="Permalink to this headline">¶</a></h4>
<p>For more complex deployments it is also possible to provide custom <cite>cassandra.yaml</cite> and <cite>jvm.options</cite> files as shown below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/&lt;fsdax-mountpoint&gt;,target<span class="o">=</span>/mnt/pmem -it  --ulimit <span class="nv">nofile</span><span class="o">=</span><span class="m">262144</span>:262144 --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/&lt;path-to-file&gt;/cassandra.yaml,target<span class="o">=</span>/workspace/cassandra/conf/cassandra.yaml --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/path-to-file&gt;/jvm.options,target<span class="o">=</span>/workspace/cassandra/conf/jvm.options --name cassandra-custom-files
</pre></div>
</div>
</div>
</div>
<div class="section" id="clustering">
<h3>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h3>
<p>For a simple two node cluster using PMEM in <cite>fsdax</cite> mode on both containers:</p>
<div class="section" id="node-1">
<h4>Node 1<a class="headerlink" href="#node-1" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>IP: 172.17.0.2</p></li>
<li><p>PMEM mountpoint: /mnt/pmem1</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/mnt/pmem1,target<span class="o">=</span>/mnt/pmem  --ulimit <span class="nv">nofile</span><span class="o">=</span><span class="m">262144</span>:262144 -it -e <span class="s1">&#39;CASSANDRA_FSDAX_POOL_SIZE_GB=2&#39;</span> -e <span class="s1">&#39;CASSANDRA_SEED_ADDRESSES=172.17.0.2:7000,172.17.0.3:7000&#39;</span>  --name cassandra-node1 &lt;image-id&gt;
</pre></div>
</div>
</div>
<div class="section" id="node-2">
<h4>Node 2<a class="headerlink" href="#node-2" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>IP: 172.17.0.3</p></li>
<li><p>PMEM mountpoint: /mnt/pmem2</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/mnt/pmem2,target<span class="o">=</span>/mnt/pmem  --ulimit <span class="nv">nofile</span><span class="o">=</span><span class="m">262144</span>:262144 -it -e <span class="s1">&#39;CASSANDRA_FSDAX_POOL_SIZE_GB=2&#39;</span> -e <span class="s1">&#39;CASSANDRA_SEED_ADDRESSES=172.17.0.2:7000,172.17.0.3:7000&#39;</span>  --name cassandra-node2 &lt;image-id&gt;
</pre></div>
</div>
<p>Once both nodes are running, eventually the gossip is settled and we can use <cite>nodetool</cite> on either container to check cluster status.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker <span class="nb">exec</span> -it &lt;container-id&gt; bash /workspace/cassandra/bin/nodetool status
</pre></div>
</div>
<p>The output should look similar to this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Datacenter: datacenter1</span>
<span class="go">=======================</span>
<span class="go">Status=Up/Down</span>
<span class="go">|/ State=Normal/Leaving/Joining/Moving</span>
<span class="go">--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack</span>
<span class="go">UN  172.17.0.3  0 bytes    256          100.0%            22387159-8192-41cf-8b6c-8bf0e1049eb7  rack1</span>
<span class="go">UN  172.17.0.2  0 bytes    256          100.0%            219b56ba-c07c-400b-a018-a5dc20edeb09  rack1</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="persistence">
<h3>Persistence<a class="headerlink" href="#persistence" title="Permalink to this headline">¶</a></h3>
<p>By default you can access the data written to Apache Cassandra  as long as the container exists. In order to persist the data past that, you can mount volumes or bind mounts on <code class="file docutils literal notranslate"><span class="pre">/workspace/cassandra/data</span></code> and <code class="file docutils literal notranslate"><span class="pre">/workspace/cassandra/logs</span></code> and in this way the data can still be accessed once the container is deleted.</p>
</div>
</div>
<div class="section" id="deploy-an-apache-cassandra-pmem-cluster-on-kubernetes">
<h2><a class="toc-backref" href="#id9">Deploy An Apache Cassandra-PMEM cluster on Kubernetes*</a><a class="headerlink" href="#deploy-an-apache-cassandra-pmem-cluster-on-kubernetes" title="Permalink to this headline">¶</a></h2>
<p>Many containerized workloads are deployed in clusters and orchestration software like Kubernetes can be useful. We will use the <a class="reference external" href="https://github.com/clearlinux/dockerfiles/tree/master/stacks/dbrs/cassandra/cassandra-pmem-helm">cassandra-pmem-helm</a> Helm* chart in this example.</p>
<div class="section" id="id1">
<h3>Requirements<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Kubectl* must be configured to access the Kubernetes Cluster</p></li>
<li><p>A Kubernetes cluster with <a class="reference external" href="https://github.com/intel/pmem-csi/blob/release-0.6/README.md">pmem-csi</a> enabled</p></li>
<li><p>The Kubernetes cluster must have <a class="reference external" href="https://helm.sh/">helm</a> and tiller installed</p></li>
<li><p>PMEM hardware</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>When selecting the <cite>fsdax</cite> pool file size, it is important to consider that when requesting a volume, certain amount of space is used by the filesystem metadata on that volume and the available space turns out to be less than total amount specified. Taking this into consideration the size of the fsdax pool file should be ~2G less than the total volume size requested.</p>
</div>
</div>
<div class="section" id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h3>
<p>In order to configure the Apache Cassandra PMEM cluster some variables and values are provided. These values are set in <code class="file docutils literal notranslate"><span class="pre">test/cassandra-pmem-helm/values.yaml</span></code>, and can be modified according to your specific needs. A summary of those parameters is shown below:</p>
<ul class="simple">
<li><p>clusterName:  The cluster Name set across all deployed nodes</p></li>
<li><p>replicaCount:  The number of nodes in the cluster to be deployed</p></li>
<li><p>image.repository:  The address of the container registry where the cassandra-pmem image should be pulled</p></li>
<li><p>image.tag:  The tag of the image to be pulled during deployment</p></li>
<li><p>image.name:  The name of the image to be pulled during deployment</p></li>
<li><p>pmem.containerPmemAllocation:  The size of the persistent volume claim to be used as heap, it uses the storage class <cite>pmem-csi-sc-ext4</cite> from pmem-csi  The size of the fsdax pool to be created inside the persistent volume claim, in practice it should be <cite>1G</cite> less than pmem.containerPmemAllocation</p></li>
<li><p>pmem.fsdaxPoolSizeInGB: The size of the fsdax pool to be created inside the persistent volume claim, in practice it should be 1G less than pmem.containerPmemAllocation</p></li>
<li><p>enablePersistence: If set to <cite>true</cite>, K8s persistent volumes are deployed to store data and logs</p></li>
<li><p>persistentVolumes.logsVolumeSize:  The size of the persistent volume used for storing logs on each node, the default is <cite>4G</cite></p></li>
<li><p>persistentVolumes.dataVolumeSize:  The size of the persistent volume used for storing data on each node, the default is <cite>4G</cite></p></li>
<li><p>persistentVolumes.logsStorageClass:  Storage class used by  the logs pvc, by default it uses <cite>pmem-csi-sc-ext4</cite></p></li>
<li><p>persistentVolumes.dataStorageClass:  Storage class used by  the data pvc, by default it uses <cite>pmem-csi-sc-ext4</cite></p></li>
<li><p>provideCustomConfig:  If set to <cite>true</cite>, it mounts all the files located on <cite>&lt;helm-chart-dir&gt;/files/conf</cite> on <cite>/workspace/cassandra/conf</cite> inside each container in order to provide a way to customize the deployment beyond the options provided here</p></li>
<li><p>exposeJmxPort:  When set to <cite>true</cite> it exposes the JMX port as part of the Kubernetes headless service. It should be used together with <cite>enableAdditionalFilesConfigMap</cite> in order to provide authentication files needed for JMX when the remote connections are allowed. When set to <cite>false</cite> only local access through 127.0.0.1 is granted and no additional authentication is needed.</p></li>
<li><p>enableClientToolsPod:  If set to <cite>true</cite>, an additional pod independent from the cluster is deployed, this pod contains various Cassandra client tools and mounts test profiles located under <cite>&lt;helm-chart-dir&gt;/files/testProfiles</cite> to <cite>/testProfiles</cite> inside the pod. This pod is useful to test and launch benchmarks</p></li>
<li><p>enableAdditionalFilesConfigMap:  When set to true, it takes the files located in <cite>&lt;helm-chart-dir&gt;/files/additionalFiles</cite> and mount them in <cite>/etc/cassandra</cite> inside the pods, some additional files for cassandra can be stored here, such as JMX auth files</p></li>
<li><p>jvmOpts.enabled:  If set to <cite>true</cite> the environment variable <cite>JVM_OPTS</cite> is overridden with the value provided on jvmOpts.value</p></li>
<li><p>jvmOpts.value: Sets the value of the environment variable <cite>JVM_OPTS</cite>, in this way some java runtime configurations can be provided such as RAM heap usage</p></li>
<li><p>resources.enabled:  if set to <cite>true</cite>, the resource constraints are set on each pod using the values under resources.requests and resources.limits</p></li>
<li><p>resources.requests.memory: Initial resource allocation for each pod in the cluster</p></li>
<li><p>resources.request.cpu: Initial resource allocation for each pod in the cluster</p></li>
<li><p>resources.limits.memory:  Limits for memory allocation for each pod in the cluster</p></li>
<li><p>resources.limits.cpu: Limits for cpu allocation for each pod in the cluster</p></li>
</ul>
</div>
<div class="section" id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h3>
<p>Once all the configurations are set, to install the chart inside a given Kubernetes cluster you must run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install ./cassandra-pmem-helm
</pre></div>
</div>
<p>Eventually all the given nodes will be shown as running using <strong class="command">kubectl get pods</strong>.</p>
</div>
</div>
<div class="section" id="running-dbrs-with-redis">
<h2><a class="toc-backref" href="#id10">Running DBRS with Redis</a><a class="headerlink" href="#running-dbrs-with-redis" title="Permalink to this headline">¶</a></h2>
<p>The Redis stack application is enabled for a multinode Kubernetes environment using Intel® Optane™ DCPMM PMem DIMMs in fsdax mode for storage.</p>
<p>The source code used for this application can be found in the <a class="reference external" href="https://github.com/pmem/pmem-redis">Github repository</a></p>
<p>The following examples will use the <a class="reference external" href="https://hub.docker.com/r/clearlinux/stacks-dbrs-redis">Docker image with Redis</a>.  You can also build your own image with Docker by using the <code class="file docutils literal notranslate"><span class="pre">Dockerfile</span></code> and running with this command</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker build --force-rm --no-cache -f Dockerfile -t <span class="si">${</span><span class="nv">DOCKER_IMAGE</span><span class="si">}</span> .
</pre></div>
</div>
<div class="section" id="single-node">
<h3>Single node<a class="headerlink" href="#single-node" title="Permalink to this headline">¶</a></h3>
<p>Prior to starting the container, you will need to have the Intel® Optane™ DCPMM module in fsdax with a file system and mounted in <cite>/mnt/dax0</cite> as shown above.</p>
<p>Use the following to start the container, replacing ${DOCKER_IMAGE} with the name of the image you are using.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/mnt/dax0,target<span class="o">=</span>/mnt/pmem0 -i -d --name pmem-redis <span class="si">${</span><span class="nv">DOCKER_IMAGE</span><span class="si">}</span> --nvm-maxcapacity <span class="m">200</span> --nvm-dir /mnt/pmem0 --nvm-threshold <span class="m">64</span> --protected-mode no
</pre></div>
</div>
</div>
<div class="section" id="redis-operator-in-a-kubernetes-cluster">
<h3>Redis Operator in a Kubernetes cluster<a class="headerlink" href="#redis-operator-in-a-kubernetes-cluster" title="Permalink to this headline">¶</a></h3>
<p>After following the  <a class="reference external" href="https://docs.01.org/clearlinux/latest/tutorials/kubernetes.html">Kubernetes guide</a> in Clear Linux OS, you will need to enable it to support DCPMM using the pmem-cls driver.  To install the driver follow the instructions in the <a class="reference external" href="https://github.com/intel/pmem-csi/blob/release-0.6/README.md">pmem-csi</a> repository.</p>
<p>We are using source code from the <a class="reference external" href="https://github.com/spotahome/redis-operator">Redis operator</a> .</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you already have a redis-operator, you will need to delete it before installing a new one.</p>
</div>
<p>After installing the operator you are ready to deploy redisfailover instances using a yaml file, like this <a class="reference external" href="https://github.com/spotahome/redis-operator/blob/master/example/redisfailover/pmem.yaml">example for persistent memory</a>. You can download it and change the source of the image to reflect your environment. We have named our yaml <cite>redis-failover.yml</cite></p>
<p>To start a redisfailover instance in Kubernetes run the following</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create -f redis-failover.yml
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>There is a <a class="reference external" href="https://github.com/spotahome/redis-operator/issues/176">known issue</a> in which the sentinels do not have enough memory to create the InitContainer. The current workaround is to build the image increasing the limits for the InitContainer memory to 32Mb</p>
</div>
</div>
</div>
<div class="section" id="running-dbrs-with-memcached">
<h2><a class="toc-backref" href="#id11">Running DBRS with Memcached</a><a class="headerlink" href="#running-dbrs-with-memcached" title="Permalink to this headline">¶</a></h2>
<p>With DBRS V2.0 you can use the DBRS stack with <a class="reference external" href="https://memcached.org">Memcached</a>, a free and open source, high performance, distributed meory object caching system. This stack is ready to use DCPMM in fsdax for storage.   The source for this application can be found in the <a class="reference external" href="https://memcached.org">Memcached</a> repository.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The DBRS v2.0 release does not support Redis or Cassandra.</p>
</div>
<div class="section" id="build-the-dbrs-memcached-image">
<h3>Build the DBRS Memcached image<a class="headerlink" href="#build-the-dbrs-memcached-image" title="Permalink to this headline">¶</a></h3>
<p>To build the Memcached enabled image, use the Dockerfile with this command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker build --force-rm --no-cache -f Dockerfile -t <span class="si">${</span><span class="nv">DOCKER_IMAGE</span><span class="si">}</span> .
</pre></div>
</div>
</div>
<div class="section" id="run-dbrs-with-memcached-as-a-standalone-container">
<h3>Run DBRS with Memcached as a standalone container<a class="headerlink" href="#run-dbrs-with-memcached-as-a-standalone-container" title="Permalink to this headline">¶</a></h3>
<p>Prior to launching the container, you will need to configure the DCPMM in fsdax mode with a file system, and have it mounted in <code class="file docutils literal notranslate"><span class="pre">/mnt/dax0</span></code>. Instructions for configuration can be found in <a class="reference internal" href="#dbrs-hardware-configuration"><span class="std std-ref">Hardware Configuration</span></a>.</p>
<p>To launch the container run this command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run --mount <span class="nv">type</span><span class="o">=</span>bind,source<span class="o">=</span>/mnt/dax0,target<span class="o">=</span>/mnt/pmem0 -i -d --name pmem-memchached <span class="si">${</span><span class="nv">DOCKER_IMAGE</span><span class="si">}</span> -e /mnt/pmem0/memcached.file -m <span class="m">64</span> -c <span class="m">1024</span> -p <span class="m">11211</span>
</pre></div>
</div>
<p>where:</p>
<p><strong class="command">-m</strong> is the maximum memory limit to use in megabytes
<strong class="command">-e</strong> is the mmap path for external memory (DCPMM storage).  For this container the DCPMM sould be mounted inside the container on <code class="file docutils literal notranslate"><span class="pre">/mnt/pmem0</span></code>
<strong class="command">-c</strong> is the number of concurrent connections
<strong class="command">-p</strong> is the TCP connection port.</p>
<p>For more information please refer to this <a class="reference external" href="https://memcached.org/blog/persistent-memory/">blog post</a> from <a class="reference external" href="https://memcached.org">Memcached</a></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="clearlinux/redis/README.html" class="btn btn-neutral float-right" title="Database Reference Stack with Redis" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="terms_of_use.html" class="btn btn-neutral float-left" title="Database Reference Stack Terms of Use" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>